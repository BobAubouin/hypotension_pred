{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aubouinb/ownCloud/Code/hypotension_pred/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "from hp_pred.experiments import objective_xgboost, bootstrap_test, create_balanced_cv\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_FEATURE = ['mbp', 'sbp', 'dbp', 'hr', 'rr', 'spo2', 'etco2', 'mac', 'pp_ct']\n",
    "STATIC_FEATURE = [\"age\", \"bmi\", \"asa\", \"preop_cr\", \"preop_htn\"]\n",
    "HALF_TIME_FILTERING = [10, 60, 60*5]\n",
    "\n",
    "FEATURE_NAME = (\n",
    "    [\n",
    "        f\"{signal}_ema_{half_time}\"\n",
    "        for signal in SIGNAL_FEATURE\n",
    "        for half_time in HALF_TIME_FILTERING\n",
    "    ]\n",
    "    + [\n",
    "        f\"{signal}_std_{half_time}\"\n",
    "        for signal in SIGNAL_FEATURE\n",
    "        for half_time in HALF_TIME_FILTERING\n",
    "    ]\n",
    "    + STATIC_FEATURE\n",
    ")\n",
    "\n",
    "BASELINE_FEATURE_NAME = 'mbp_ema_10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data frame and add the meta data to the segments\n",
    "data = pd.read_parquet(Path('data/datasets/base_dataset_no_leading_time/cases/'))\n",
    "\n",
    "static = pd.read_parquet('data/datasets/base_dataset_no_leading_time/meta.parquet')\n",
    "\n",
    "data = data.merge(static, on='caseid')\n",
    "\n",
    "data.asa = data.asa.astype(int)\n",
    "data.preop_htn = data.preop_htn.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train or load existing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leading time: 0\n",
      "105753 train samples and 40545 test samples, positive rate = 0.07\n",
      "leading time: 2\n",
      "104142 train samples and 39882 test samples, positive rate = 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in cast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leading time: 4\n",
      "102618 train samples and 39257 test samples, positive rate = 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leading time: 6\n",
      "101177 train samples and 38704 test samples, positive rate = 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n",
      "invalid value encountered in cast\n"
     ]
    }
   ],
   "source": [
    "# control reproducibility\n",
    "rng_seed = 42\n",
    "\n",
    "result_folder = Path(\"data/results\")\n",
    "if not result_folder.exists():\n",
    "    result_folder.exists()\n",
    "\n",
    "for leading_time in range(0,7,2):\n",
    "    data_lead = data[(data.time_before_IOH >= leading_time*60) | (data.time_before_IOH.isna())]\n",
    "\n",
    "    train = data_lead[data_lead['split'] == \"train\"]\n",
    "    test = data_lead[data_lead['split'] == \"test\"]\n",
    "\n",
    "    train = train.dropna(subset=FEATURE_NAME)\n",
    "    test = test.dropna(subset=FEATURE_NAME)\n",
    "    print('leading time:', leading_time)\n",
    "    print(\n",
    "        f'{len(train)} train samples and {len(test)} test samples, positive rate = {test[\"label\"].mean():.2f}'\n",
    "    )\n",
    "\n",
    "    # Set model file, create models folder if does not exist.\n",
    "    model_folder = Path(\"data/models\")\n",
    "    if not model_folder.exists():\n",
    "        model_folder.mkdir()\n",
    "    model_file = model_folder / f\"xgb.json\"\n",
    "\n",
    "    # create a regressor\n",
    "    if model_file.exists():\n",
    "        model = xgb.XGBClassifier()\n",
    "        model.load_model(model_file)\n",
    "    else:\n",
    "        # creat an optuna study\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(\n",
    "            lambda trial: objective_xgboost(trial, train, FEATURE_NAME, train_cv_split),\n",
    "            n_trials=80,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "\n",
    "        # get the best hyperparameters\n",
    "        best_params = study.best_params\n",
    "\n",
    "        model = xgb.XGBClassifier(**best_params)\n",
    "        # refit the model with best parameters\n",
    "        model.fit(train[FEATURE_NAME], train.label, verbose=1)\n",
    "\n",
    "        # save the model\n",
    "        model.save_model(model_file)\n",
    "\n",
    "    # test the model\n",
    "    y_pred = model.predict_proba(test[FEATURE_NAME])[:, 1]\n",
    "    y_test = test[\"label\"].values\n",
    "    y_label_id = test[\"label_id\"].values\n",
    "\n",
    "    df_results, _ = bootstrap_test(y_test, y_pred, y_label_id, n_bootstraps=200, rng_seed=rng_seed)\n",
    "\n",
    "    roc_results = result_folder / f\"xgboost_roc_lead_{leading_time}.csv\"\n",
    "    df_results.to_csv(roc_results, index=False)\n",
    "\n",
    "    # test baseline\n",
    "    y_pred_baseline = 1 - test[BASELINE_FEATURE_NAME].values/120\n",
    "\n",
    "    df_results_baseline, _ = bootstrap_test(y_test, y_pred_baseline, y_label_id, n_bootstraps=200, rng_seed=rng_seed)\n",
    "\n",
    "    roc_results = result_folder / f\"baseline_roc_lead_{leading_time}.csv\"\n",
    "    df_results_baseline.to_csv(roc_results, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/results/xgboost_roc_lead_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/aubouinb/ownCloud/Code/hypotension_pred/scripts/experiments/study_leading_time.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aubouinb/ownCloud/Code/hypotension_pred/scripts/experiments/study_leading_time.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lead_time_list\u001b[39m.\u001b[39mappend(leading_time)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aubouinb/ownCloud/Code/hypotension_pred/scripts/experiments/study_leading_time.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m roc_results \u001b[39m=\u001b[39m result_folder \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mxgboost_roc_lead_\u001b[39m\u001b[39m{\u001b[39;00mleading_time\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aubouinb/ownCloud/Code/hypotension_pred/scripts/experiments/study_leading_time.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(roc_results)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aubouinb/ownCloud/Code/hypotension_pred/scripts/experiments/study_leading_time.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m xgboost_auc_list\u001b[39m.\u001b[39mappend(df_results\u001b[39m.\u001b[39mauc[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aubouinb/ownCloud/Code/hypotension_pred/scripts/experiments/study_leading_time.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m xgboost_auc_std_list\u001b[39m.\u001b[39mappend(df_results\u001b[39m.\u001b[39mauc_std[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/ownCloud/Code/hypotension_pred/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/ownCloud/Code/hypotension_pred/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/ownCloud/Code/hypotension_pred/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/ownCloud/Code/hypotension_pred/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/ownCloud/Code/hypotension_pred/.venv/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/results/xgboost_roc_lead_0.csv'"
     ]
    }
   ],
   "source": [
    "xgboost_auc_list, baseline_auc_list, lead_time_list = [], [], []\n",
    "xgboost_auc_std_list, baseline_auc_std_list = [], []\n",
    "\n",
    "for leading_time in range(0,7,2):\n",
    "    lead_time_list.append(leading_time)\n",
    "    roc_results = result_folder / f\"xgboost_roc_lead_{leading_time}.csv\"\n",
    "    df_results = pd.read_csv(roc_results)\n",
    "    xgboost_auc_list.append(df_results.auc[0])\n",
    "    xgboost_auc_std_list.append(df_results.auc_std[0])\n",
    "\n",
    "    roc_results = result_folder / f\"baseline_roc_lead_{leading_time}.csv\"\n",
    "    df_results = pd.read_csv(roc_results)\n",
    "    baseline_auc_list.append(df_results.auc[0])\n",
    "    baseline_auc_std_list.append(df_results.auc_std[0])\n",
    "    \n",
    "\n",
    "plt.errorbar(lead_time_list, xgboost_auc_list,xgboost_auc_std_list, fmt='-o', label='model', capsize=6)\n",
    "plt.errorbar(lead_time_list, baseline_auc_list, baseline_auc_std_list, fmt='-o', label='baseline', capsize=6)\n",
    "plt.xlabel('Leading time (min)')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#save the data\n",
    "auc_df = pd.DataFrame({'lead_time': lead_time_list, 'xgboost_auc': xgboost_auc_list, 'xgboost_auc_std': xgboost_auc_std_list, 'baseline_auc': baseline_auc_list, 'baseline_auc_std': baseline_auc_std_list})\n",
    "auc_df.to_csv(result_folder / 'auc_lead_time.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control reproducibility\n",
    "rng_seed = 42\n",
    "\n",
    "result_folder = Path(\"data/results\")\n",
    "if not result_folder.exists():\n",
    "    result_folder.exists()\n",
    "\n",
    "for leading_time in range(0,7,2):\n",
    "    data_lead = data[(data.time_before_IOH >= leading_time*60) | (data.time_before_IOH.isna())]\n",
    "\n",
    "    train = data_lead[data_lead['split'] == \"train\"]\n",
    "    test = data_lead[data_lead['split'] == \"test\"]\n",
    "\n",
    "    train_case_label = train.groupby(\"caseid\").agg(\n",
    "                segment_count=(\"label\", \"count\"),\n",
    "                label_count=(\"label\", \"sum\"),\n",
    "            )\n",
    "\n",
    "    # train_cv_split = create_balanced_cv(train_case_label, nb_max_iter=100000)\n",
    "\n",
    "\n",
    "    \n",
    "    train = train.dropna(subset=FEATURE_NAME)\n",
    "    test = test.dropna(subset=FEATURE_NAME)\n",
    "    print('leading time:', leading_time)\n",
    "    print(\n",
    "        f'{len(train)} train samples and {len(test)} test samples, positive rate = {test[\"label\"].mean():.2f}'\n",
    "    )\n",
    "\n",
    "    # Set model file, create models folder if does not exist.\n",
    "    model_folder = Path(\"data/models\")\n",
    "    if not model_folder.exists():\n",
    "        model_folder.mkdir()\n",
    "    model_file = model_folder / f\"xgb_lead_{0}.json\"\n",
    "\n",
    "    # create a regressor\n",
    "    if model_file.exists():\n",
    "        model = xgb.XGBClassifier()\n",
    "        model.load_model(model_file)\n",
    "    else:\n",
    "        # creat an optuna study\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(\n",
    "            lambda trial: objective_xgboost(trial, train, FEATURE_NAME, train_cv_split),\n",
    "            n_trials=80,\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "\n",
    "        # get the best hyperparameters\n",
    "        best_params = study.best_params\n",
    "\n",
    "        model = xgb.XGBClassifier(**best_params)\n",
    "        # refit the model with best parameters\n",
    "        model.fit(train[FEATURE_NAME], train.label, verbose=1)\n",
    "\n",
    "        # save the model\n",
    "        model.save_model(model_file)\n",
    "\n",
    "    # test the model\n",
    "    y_pred = model.predict_proba(test[FEATURE_NAME])[:, 1]\n",
    "    y_test = test[\"label\"].values\n",
    "    y_label_id = test[\"label_id\"].values\n",
    "\n",
    "    df_results, _ = bootstrap_test(y_test, y_pred, y_label_id, n_bootstraps=200, rng_seed=rng_seed)\n",
    "    \n",
    "    roc_results = result_folder / f\"xgboost_roc_lead_{leading_time}.csv\"\n",
    "    df_results.to_csv(roc_results, index=False)\n",
    "\n",
    "    #test baseline\n",
    "    y_pred_baseline = 1 - test[BASELINE_FEATURE_NAME].values/120\n",
    "\n",
    "    df_results_baseline, _ = bootstrap_test(y_test, y_pred_baseline, y_label_id, n_bootstraps=200, rng_seed=rng_seed)\n",
    "\n",
    "    roc_results = result_folder / f\"baseline_roc_lead_{leading_time}.csv\"\n",
    "    df_results_baseline.to_csv(roc_results, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_auc_list, baseline_auc_list, lead_time_list = [], [], []\n",
    "xgboost_auc_std_list, baseline_auc_std_list = [], []\n",
    "\n",
    "for leading_time in range(0,7,2):\n",
    "    lead_time_list.append(leading_time)\n",
    "    roc_results = result_folder / f\"xgboost_roc_lead_{leading_time}.csv\"\n",
    "    df_results = pd.read_csv(roc_results)\n",
    "    xgboost_auc_list.append(df_results.auc[0])\n",
    "    xgboost_auc_std_list.append(df_results.auc_std[0])\n",
    "\n",
    "    roc_results = result_folder / f\"baseline_roc_lead_{leading_time}.csv\"\n",
    "    df_results = pd.read_csv(roc_results)\n",
    "    baseline_auc_list.append(df_results.auc[0])\n",
    "    baseline_auc_std_list.append(df_results.auc_std[0])\n",
    "    \n",
    "\n",
    "plt.errorbar(lead_time_list, xgboost_auc_list,xgboost_auc_std_list, fmt='-o', label='model', capsize=6)\n",
    "plt.errorbar(lead_time_list, baseline_auc_list, baseline_auc_std_list, fmt='-o', label='baseline', capsize=6)\n",
    "plt.xlabel('Leading time (min)')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#save the data\n",
    "auc_df = pd.DataFrame({'lead_time': lead_time_list, 'xgboost_auc': xgboost_auc_list, 'xgboost_auc_std': xgboost_auc_std_list, 'baseline_auc': baseline_auc_list, 'baseline_auc_std': baseline_auc_std_list})\n",
    "auc_df.to_csv(result_folder / 'auc_lead_time.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_auc_std_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
